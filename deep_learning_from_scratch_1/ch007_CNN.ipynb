{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss:2.2998219148811465\n",
      "=== epoch:1, train acc:0.248, test acc:0.258 ===\n",
      "train loss:2.2973560359674057\n",
      "train loss:2.2926730604876058\n",
      "train loss:2.285661943209526\n",
      "train loss:2.2741045195977105\n",
      "train loss:2.26604922385052\n",
      "train loss:2.2395603528083416\n",
      "train loss:2.238831309886666\n",
      "train loss:2.1890282876565683\n",
      "train loss:2.183701169229033\n",
      "train loss:2.1390316364965263\n",
      "train loss:2.1204028379926236\n",
      "train loss:2.0435667491059593\n",
      "train loss:2.006998334133458\n",
      "train loss:2.0158506823679145\n",
      "train loss:1.9822552390839108\n",
      "train loss:1.9075136522830303\n",
      "train loss:1.775045163290058\n",
      "train loss:1.7618679397717285\n",
      "train loss:1.6671187936677967\n",
      "train loss:1.6382689079217065\n",
      "train loss:1.5580102204111619\n",
      "train loss:1.458337127767664\n",
      "train loss:1.399025057075166\n",
      "train loss:1.3466142988239957\n",
      "train loss:1.2201382349425396\n",
      "train loss:1.2293419617608508\n",
      "train loss:1.0495437742365596\n",
      "train loss:1.0361181192602864\n",
      "train loss:1.0772989747653197\n",
      "train loss:0.9557326849536157\n",
      "train loss:0.9761823430298249\n",
      "train loss:0.9083150727712238\n",
      "train loss:0.9536258403268163\n",
      "train loss:0.7286983741903669\n",
      "train loss:0.9221414893679574\n",
      "train loss:0.6576397180521063\n",
      "train loss:0.6403350937426576\n",
      "train loss:0.5247285399934495\n",
      "train loss:0.7721133239588872\n",
      "train loss:0.5847798508783808\n",
      "train loss:0.5324207067996994\n",
      "train loss:0.6174564453479139\n",
      "train loss:0.6304371546049605\n",
      "train loss:0.5195181678582663\n",
      "train loss:0.7172271093007041\n",
      "train loss:0.5094220536294098\n",
      "train loss:0.7614182386837139\n",
      "train loss:0.7632851387217624\n",
      "train loss:0.5467331196493448\n",
      "train loss:0.5093454459173989\n",
      "train loss:0.5252418798363943\n",
      "train loss:0.836481364333782\n",
      "train loss:0.5009477035751008\n",
      "train loss:0.6459389474958482\n",
      "train loss:0.682315589914451\n",
      "train loss:0.5939703718915387\n",
      "train loss:0.40858781100026076\n",
      "train loss:0.6426552125827407\n",
      "train loss:0.5455715654352961\n",
      "train loss:0.5372555573176669\n",
      "train loss:0.5004580918153417\n",
      "train loss:0.6005357258654765\n",
      "train loss:0.33967099430664843\n",
      "train loss:0.6729136512425415\n",
      "train loss:0.4110653982364449\n",
      "train loss:0.45803359901455143\n",
      "train loss:0.28601795880474185\n",
      "train loss:0.5725964532292366\n",
      "train loss:0.6261527159247698\n",
      "train loss:0.570308832767564\n",
      "train loss:0.6300937392299634\n",
      "train loss:0.6163159243275866\n",
      "train loss:0.6719892653330756\n",
      "train loss:0.345371242162859\n",
      "train loss:0.44318268032486974\n",
      "train loss:0.3889254579605462\n",
      "train loss:0.4448613490684019\n",
      "train loss:0.47674316938162425\n",
      "train loss:0.36414481226802947\n",
      "train loss:0.3885817810287277\n",
      "train loss:0.29829212552808015\n",
      "train loss:0.45415155882179503\n",
      "train loss:0.5759992377534534\n",
      "train loss:0.44039976187112634\n",
      "train loss:0.5041582852225057\n",
      "train loss:0.3354053263989419\n",
      "train loss:0.25962278832566754\n",
      "train loss:0.4436157971112744\n",
      "train loss:0.5166977633111088\n",
      "train loss:0.4505938019036593\n",
      "train loss:0.43386064376723\n",
      "train loss:0.26118059949792366\n",
      "train loss:0.4562590359132468\n",
      "train loss:0.5298821996221137\n",
      "train loss:0.5015881476968131\n",
      "train loss:0.3706621023857377\n",
      "train loss:0.44601669268810823\n",
      "train loss:0.5817397399175761\n",
      "train loss:0.543767388512961\n",
      "train loss:0.42698994237609095\n",
      "train loss:0.3398752979033864\n",
      "train loss:0.29998701352188845\n",
      "train loss:0.4923914680506549\n",
      "train loss:0.4141529438180653\n",
      "train loss:0.5038881151207526\n",
      "train loss:0.22011063198585956\n",
      "train loss:0.32597626155299475\n",
      "train loss:0.3285669708719696\n",
      "train loss:0.33228101499568913\n",
      "train loss:0.4012668611475302\n",
      "train loss:0.4215913000077673\n",
      "train loss:0.3340612745129057\n",
      "train loss:0.2585032273424021\n",
      "train loss:0.34286524667233254\n",
      "train loss:0.2892287349970536\n",
      "train loss:0.3853803421147846\n",
      "train loss:0.268859518831249\n",
      "train loss:0.4769455328349395\n",
      "train loss:0.4269149135451016\n",
      "train loss:0.27030470198432366\n",
      "train loss:0.46808303496067977\n",
      "train loss:0.2817252279534415\n",
      "train loss:0.4210160902546465\n",
      "train loss:0.3435832653373744\n",
      "train loss:0.4478800076800747\n",
      "train loss:0.43630928511810263\n",
      "train loss:0.29662279762192767\n",
      "train loss:0.39430358468530957\n",
      "train loss:0.4947508812732957\n",
      "train loss:0.3111867757541952\n",
      "train loss:0.3064120572372303\n",
      "train loss:0.2935370920148847\n",
      "train loss:0.3575633751045536\n",
      "train loss:0.29230250325137724\n",
      "train loss:0.3623900423478998\n",
      "train loss:0.31447928816479886\n",
      "train loss:0.4012710898909051\n",
      "train loss:0.49222010818774947\n",
      "train loss:0.34383652955892763\n",
      "train loss:0.31616533738143626\n",
      "train loss:0.39787824178409004\n",
      "train loss:0.3177566372677792\n",
      "train loss:0.3102146439734142\n",
      "train loss:0.47588821946412685\n",
      "train loss:0.39275717180413217\n",
      "train loss:0.2645297735672406\n",
      "train loss:0.268148647411996\n",
      "train loss:0.2630482972214104\n",
      "train loss:0.32135757483226174\n",
      "train loss:0.22937000059897694\n",
      "train loss:0.5519939712222063\n",
      "train loss:0.3251166454060387\n",
      "train loss:0.4073886241350301\n",
      "train loss:0.19371653921927276\n",
      "train loss:0.3429203165753277\n",
      "train loss:0.368123775063299\n",
      "train loss:0.3759281022208181\n",
      "train loss:0.5531830429495508\n",
      "train loss:0.3388691855822266\n",
      "train loss:0.27670383355508704\n",
      "train loss:0.268706928224259\n",
      "train loss:0.40826175207893134\n",
      "train loss:0.26269268594709105\n",
      "train loss:0.3541152190477387\n",
      "train loss:0.2513170163992595\n",
      "train loss:0.27532257770512203\n",
      "train loss:0.44529142084047746\n",
      "train loss:0.2117067479488663\n",
      "train loss:0.39101139464803775\n",
      "train loss:0.361438833347742\n",
      "train loss:0.26058216866707584\n",
      "train loss:0.31138843215793144\n",
      "train loss:0.2524800495096797\n",
      "train loss:0.27730269661377455\n",
      "train loss:0.21108192800451941\n",
      "train loss:0.1864366028372779\n",
      "train loss:0.24962571037289222\n",
      "train loss:0.25539470721979324\n",
      "train loss:0.24605015925554763\n",
      "train loss:0.2730822280986396\n",
      "train loss:0.32017088544842204\n",
      "train loss:0.2581687855339563\n",
      "train loss:0.3212939148520948\n",
      "train loss:0.29576399681637855\n",
      "train loss:0.496466358013962\n",
      "train loss:0.28698113533000563\n",
      "train loss:0.17797109314742557\n",
      "train loss:0.5178881072631227\n",
      "train loss:0.24013700535647145\n",
      "train loss:0.27566883304571027\n",
      "train loss:0.3614757969419693\n",
      "train loss:0.37387847148480646\n",
      "train loss:0.2856688624628466\n",
      "train loss:0.48942982801685503\n",
      "train loss:0.4208556658023522\n",
      "train loss:0.3152207622682702\n",
      "train loss:0.3389975881816462\n",
      "train loss:0.25760653769404773\n",
      "train loss:0.2448726822652293\n",
      "train loss:0.20737390770312877\n",
      "train loss:0.31002687673734725\n",
      "train loss:0.3164681759056973\n",
      "train loss:0.2668128303771074\n",
      "train loss:0.2912785993192472\n",
      "train loss:0.23717310026086705\n",
      "train loss:0.21271909097470956\n",
      "train loss:0.3513141646017564\n",
      "train loss:0.47357052414295175\n",
      "train loss:0.2506314259959407\n",
      "train loss:0.19833664773213439\n",
      "train loss:0.333819016468953\n",
      "train loss:0.257161550039539\n",
      "train loss:0.18630839436568292\n",
      "train loss:0.3580645583346559\n",
      "train loss:0.32316404763089407\n",
      "train loss:0.1871690902803963\n",
      "train loss:0.1911315863559401\n",
      "train loss:0.29918611467421935\n",
      "train loss:0.23976032023631294\n",
      "train loss:0.17981710192054087\n",
      "train loss:0.21636005627382662\n",
      "train loss:0.40034430329773707\n",
      "train loss:0.3479724743388312\n",
      "train loss:0.1822757906765244\n",
      "train loss:0.2939588547809732\n",
      "train loss:0.3693326334180467\n",
      "train loss:0.26115035218804883\n",
      "train loss:0.3671671152862933\n",
      "train loss:0.18258029926327246\n",
      "train loss:0.3694448106262474\n",
      "train loss:0.2314553069763981\n",
      "train loss:0.25223715325854196\n",
      "train loss:0.2509119951854172\n",
      "train loss:0.3330748449341507\n",
      "train loss:0.22140618214454655\n",
      "train loss:0.16333748936745704\n",
      "train loss:0.2775128232329498\n",
      "train loss:0.3241787834098786\n",
      "train loss:0.27309112527472895\n",
      "train loss:0.3834211370963777\n",
      "train loss:0.22135843015148798\n",
      "train loss:0.18748349423115354\n",
      "train loss:0.23663567049010717\n",
      "train loss:0.38605063171045556\n",
      "train loss:0.18138460089472605\n",
      "train loss:0.24779297515953647\n",
      "train loss:0.21723646779057695\n",
      "train loss:0.18169683579040657\n",
      "train loss:0.2536010617851206\n",
      "train loss:0.1397502336404316\n",
      "train loss:0.22897675213173826\n",
      "train loss:0.16885809235300925\n",
      "train loss:0.1848294024908258\n",
      "train loss:0.20211811565641502\n",
      "train loss:0.18304127468156625\n",
      "train loss:0.26052409825443074\n",
      "train loss:0.22817412667430248\n",
      "train loss:0.2537795939323708\n",
      "train loss:0.2571652115373371\n",
      "train loss:0.3663011169580719\n",
      "train loss:0.1979919955959486\n",
      "train loss:0.2552495444383973\n",
      "train loss:0.3776633993648781\n",
      "train loss:0.14630378548715645\n",
      "train loss:0.3270899832353066\n",
      "train loss:0.3187348569581217\n",
      "train loss:0.27211751684591096\n",
      "train loss:0.3335652405906423\n",
      "train loss:0.289131416987343\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss:0.30974136184231343\n",
      "train loss:0.23089725444106893\n",
      "train loss:0.27057821827867024\n",
      "train loss:0.2599538160163834\n",
      "train loss:0.2822132951223815\n",
      "train loss:0.1823348398746691\n",
      "train loss:0.24917829578213666\n",
      "train loss:0.2408939378247156\n",
      "train loss:0.22062981979481833\n",
      "train loss:0.20951121592436472\n",
      "train loss:0.13376336887506082\n",
      "train loss:0.41092558844696925\n",
      "train loss:0.2710672320799852\n",
      "train loss:0.2207719579474334\n",
      "train loss:0.1619301677194008\n",
      "train loss:0.24966927104109135\n",
      "train loss:0.42629703710964023\n",
      "train loss:0.41121390468377284\n",
      "train loss:0.26673142308297626\n",
      "train loss:0.1336811213900955\n",
      "train loss:0.2258493661434573\n",
      "train loss:0.21900481567079028\n",
      "train loss:0.19109950200359654\n",
      "train loss:0.19017564334048903\n",
      "train loss:0.17948407138623182\n",
      "train loss:0.19094061059786235\n",
      "train loss:0.23143973827902214\n",
      "train loss:0.10875737314779804\n",
      "train loss:0.22759389446186212\n",
      "train loss:0.1949945753040932\n",
      "train loss:0.27739580399678904\n",
      "train loss:0.195186973486748\n",
      "train loss:0.27292789086864444\n",
      "train loss:0.3121369265721312\n",
      "train loss:0.28185109116231444\n",
      "train loss:0.21840450970132802\n",
      "train loss:0.19118885796873056\n",
      "train loss:0.2185657772454514\n",
      "train loss:0.2721747362394278\n",
      "train loss:0.3437332951729459\n",
      "train loss:0.1394284460569793\n",
      "train loss:0.2351224358107142\n",
      "train loss:0.11357785230025036\n",
      "train loss:0.14043498031610957\n",
      "train loss:0.13768988447323344\n",
      "train loss:0.2170781105177207\n",
      "train loss:0.2880090565948711\n",
      "train loss:0.29134696703303825\n",
      "train loss:0.3472979558583955\n",
      "train loss:0.14850311838692468\n",
      "train loss:0.1772829938442613\n",
      "train loss:0.3831244104336685\n",
      "train loss:0.20778587599737786\n",
      "train loss:0.2782408040261703\n",
      "train loss:0.3359141684981102\n",
      "train loss:0.18306119794985062\n",
      "train loss:0.27509689832318157\n",
      "train loss:0.15900919745456302\n",
      "train loss:0.20703889649341917\n",
      "train loss:0.25544139982084874\n",
      "train loss:0.20428748362557897\n",
      "train loss:0.17075371494654312\n",
      "train loss:0.20588475686668203\n",
      "train loss:0.3410404030584647\n",
      "train loss:0.2209737212195125\n",
      "train loss:0.32615671939832525\n",
      "train loss:0.1863233415458822\n",
      "train loss:0.35912161903490436\n",
      "train loss:0.19240516342572836\n",
      "train loss:0.19286809303468327\n",
      "train loss:0.2493737155002063\n",
      "train loss:0.39671947361462323\n",
      "train loss:0.27979590795726317\n",
      "train loss:0.2546420569897847\n",
      "train loss:0.26768626760242226\n",
      "train loss:0.16186639310631268\n",
      "train loss:0.17196591899012734\n",
      "train loss:0.16194764045456192\n",
      "train loss:0.22058497862908497\n",
      "train loss:0.28861061242203506\n",
      "train loss:0.2166902341325888\n",
      "train loss:0.2919259425432826\n",
      "train loss:0.1637607513387704\n",
      "train loss:0.1997118134592002\n",
      "train loss:0.21329678630417054\n",
      "train loss:0.21636581824021056\n",
      "train loss:0.15736676155530124\n",
      "train loss:0.1755879799485287\n",
      "train loss:0.17404941036569876\n",
      "train loss:0.21013399955550516\n",
      "train loss:0.15788633913044742\n",
      "train loss:0.18766141215344834\n",
      "train loss:0.14476114430240916\n",
      "train loss:0.16598367760874527\n",
      "train loss:0.21679376380819412\n",
      "train loss:0.22911573567913163\n",
      "train loss:0.21062694756437722\n",
      "train loss:0.17932687423816698\n",
      "train loss:0.1017145609989412\n",
      "train loss:0.2057615987735299\n",
      "train loss:0.16805286474447764\n",
      "train loss:0.23610377052954853\n",
      "train loss:0.18910115308190992\n",
      "train loss:0.18475251949091512\n",
      "train loss:0.20413278837644694\n",
      "train loss:0.2343258803295833\n",
      "train loss:0.20222795799007032\n",
      "train loss:0.17039557416601311\n",
      "train loss:0.13587502724052208\n",
      "train loss:0.24566218027350015\n",
      "train loss:0.0936682150737106\n",
      "train loss:0.12939290772815343\n",
      "train loss:0.11236709184942077\n",
      "train loss:0.24390644082285132\n",
      "train loss:0.24629571173836975\n",
      "train loss:0.28417734685410545\n",
      "train loss:0.2938401991006901\n",
      "train loss:0.1442753373592291\n",
      "train loss:0.22687057003854982\n",
      "train loss:0.3104290678148982\n",
      "train loss:0.26540953019769165\n",
      "train loss:0.15908822151436264\n",
      "train loss:0.21430392905607407\n",
      "train loss:0.23428483858431398\n",
      "train loss:0.23887871297356292\n",
      "train loss:0.16043584496509472\n",
      "train loss:0.25318469991638115\n",
      "train loss:0.24594388967514152\n",
      "train loss:0.15407085513516336\n",
      "train loss:0.09600790856629268\n",
      "train loss:0.14899324749751297\n",
      "train loss:0.18151462977961144\n",
      "train loss:0.17292856218958721\n",
      "train loss:0.3036785281178412\n",
      "train loss:0.347171068947757\n",
      "train loss:0.19771993832334833\n",
      "train loss:0.2028645733850927\n",
      "train loss:0.1447881641711938\n",
      "train loss:0.11867207549704623\n",
      "train loss:0.2035525517294082\n",
      "train loss:0.13722008997603266\n",
      "train loss:0.17360150355704737\n",
      "train loss:0.1976862123117462\n",
      "train loss:0.17087396352641804\n",
      "train loss:0.16466489777111723\n",
      "train loss:0.16763299356407632\n",
      "train loss:0.13072046420858088\n",
      "train loss:0.16418387039461801\n",
      "train loss:0.17419663928054355\n",
      "train loss:0.43770745431226\n",
      "train loss:0.19451891648833336\n",
      "train loss:0.20020472706467182\n",
      "train loss:0.12683767392030196\n",
      "train loss:0.11681529257336919\n",
      "train loss:0.15227237629594556\n",
      "train loss:0.1622804625597445\n",
      "train loss:0.14937048738455308\n",
      "train loss:0.16079538601793708\n",
      "train loss:0.08547250272140511\n",
      "train loss:0.15856152476096783\n",
      "train loss:0.4007321453046253\n",
      "train loss:0.35921528792910484\n",
      "train loss:0.09731852602535468\n",
      "train loss:0.18549657131995392\n",
      "train loss:0.20816711106706418\n",
      "train loss:0.15995354098969616\n",
      "train loss:0.23952776687526944\n",
      "train loss:0.2202404547573891\n",
      "train loss:0.16814510650943482\n",
      "train loss:0.16236653486879074\n",
      "train loss:0.14762516378241647\n",
      "train loss:0.2663508829689223\n",
      "train loss:0.15612487506655925\n",
      "train loss:0.2551264761741977\n",
      "train loss:0.13172420667344586\n",
      "train loss:0.12737322250095745\n",
      "train loss:0.09791417364759766\n",
      "train loss:0.11193261190589675\n",
      "train loss:0.15111367209809395\n",
      "train loss:0.10615098823152155\n",
      "train loss:0.09267559718861434\n",
      "train loss:0.182087855338518\n",
      "train loss:0.13724983215530565\n",
      "train loss:0.15468476640880272\n",
      "train loss:0.12260960992553342\n",
      "train loss:0.2101724960411196\n",
      "train loss:0.20501983271014104\n",
      "train loss:0.13681545218505006\n",
      "train loss:0.15170075618499632\n",
      "train loss:0.13353435767971408\n",
      "train loss:0.28316243208730574\n",
      "train loss:0.23840373661402497\n",
      "train loss:0.09609106746072432\n",
      "train loss:0.2084547673619015\n",
      "train loss:0.1503898497313246\n",
      "train loss:0.13279133637998086\n",
      "train loss:0.27875677635635027\n",
      "train loss:0.2286795385161155\n",
      "train loss:0.198187612027481\n",
      "train loss:0.14265122108403488\n",
      "train loss:0.08046176844588444\n",
      "train loss:0.1856190632713789\n",
      "train loss:0.16618671346202799\n",
      "train loss:0.26630385444184435\n",
      "train loss:0.2454243873885356\n",
      "train loss:0.26955454366863596\n",
      "train loss:0.13235999769605772\n",
      "train loss:0.11584678496027241\n",
      "train loss:0.10581503447439541\n",
      "train loss:0.19195313407921655\n",
      "train loss:0.20375782945649618\n",
      "train loss:0.23781507737811183\n",
      "train loss:0.24680596853145811\n",
      "train loss:0.10474754439054423\n",
      "train loss:0.1681598956818287\n",
      "train loss:0.13712232263635557\n",
      "train loss:0.11440478240276394\n",
      "train loss:0.07729271999352719\n",
      "train loss:0.1005468551139067\n",
      "train loss:0.08857099537017243\n",
      "train loss:0.1640279087547921\n",
      "train loss:0.13935247922789767\n",
      "train loss:0.12676493627167779\n",
      "train loss:0.14014161034048603\n",
      "train loss:0.1738236497851423\n",
      "train loss:0.1582665615402048\n",
      "train loss:0.16584976655776276\n",
      "train loss:0.11400862349847296\n",
      "train loss:0.21237313373137162\n",
      "train loss:0.14354183072079063\n",
      "train loss:0.23093794897538342\n",
      "train loss:0.12869016676784248\n",
      "train loss:0.08226830660395329\n",
      "train loss:0.16171817719917622\n",
      "train loss:0.16381326435832905\n",
      "train loss:0.16656532701281024\n",
      "train loss:0.08261434731736976\n",
      "train loss:0.3017174855820674\n",
      "train loss:0.17205597285148172\n",
      "train loss:0.15952074401822194\n",
      "train loss:0.06574351483928276\n",
      "train loss:0.14000003873663525\n",
      "train loss:0.2685674622326573\n",
      "train loss:0.13669195312927768\n",
      "train loss:0.14913365786481791\n",
      "train loss:0.2523217218661514\n",
      "train loss:0.21676313641204525\n",
      "train loss:0.09830347670021147\n",
      "train loss:0.10453695644177027\n",
      "train loss:0.1351220262646543\n",
      "train loss:0.1921550474259609\n",
      "train loss:0.12720787538984987\n",
      "train loss:0.13643486518565315\n",
      "train loss:0.18159611968094633\n",
      "train loss:0.10719781671610734\n",
      "train loss:0.12567270737741915\n",
      "train loss:0.1344332791303321\n",
      "train loss:0.1321778710201351\n",
      "train loss:0.18036511166931835\n",
      "train loss:0.0845324109498012\n",
      "train loss:0.2052207320419727\n",
      "train loss:0.23917117776924268\n",
      "train loss:0.16754489804949887\n",
      "train loss:0.13454476483849187\n",
      "train loss:0.28328462795204323\n",
      "train loss:0.09769268520545284\n",
      "train loss:0.17095346257506405\n",
      "train loss:0.12984978313540124\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss:0.1735572423715009\n",
      "train loss:0.12445640300750664\n",
      "train loss:0.09598587423919007\n",
      "train loss:0.10868058789879476\n",
      "train loss:0.05125695565497001\n",
      "train loss:0.14384086182475564\n",
      "train loss:0.16581157205449404\n",
      "train loss:0.2700282891250905\n",
      "train loss:0.06858035112610489\n",
      "train loss:0.14914994640482357\n",
      "train loss:0.12217595744609706\n",
      "train loss:0.2294567960236078\n",
      "train loss:0.09339280735464724\n",
      "train loss:0.09771824759604013\n",
      "train loss:0.13359622664983156\n",
      "train loss:0.20861424366190207\n",
      "train loss:0.21120525316757388\n",
      "train loss:0.19770040969485636\n",
      "train loss:0.12218472441748014\n",
      "train loss:0.08120511117905542\n",
      "train loss:0.19723237872807187\n",
      "train loss:0.06005088165277457\n",
      "train loss:0.1382083822818544\n",
      "train loss:0.15706882078041637\n",
      "train loss:0.19085164927980458\n",
      "train loss:0.1259121707182819\n",
      "train loss:0.07590448680579377\n",
      "train loss:0.11173161963007491\n",
      "train loss:0.11273668517215457\n",
      "train loss:0.08448422085519017\n",
      "train loss:0.12181054390930869\n",
      "train loss:0.06403318380425145\n",
      "train loss:0.10664452260538317\n",
      "train loss:0.10786134524653454\n",
      "train loss:0.1439553289917221\n",
      "train loss:0.10742945447676036\n",
      "train loss:0.18094763326898733\n",
      "train loss:0.2170362851074523\n",
      "train loss:0.08305513842666501\n",
      "train loss:0.31957515062713054\n",
      "train loss:0.05581800892783468\n",
      "train loss:0.09912951142962743\n",
      "train loss:0.11090015121113138\n",
      "train loss:0.11072915676851663\n",
      "train loss:0.20856117560323084\n",
      "train loss:0.22164368914676483\n",
      "train loss:0.06891837030664497\n",
      "train loss:0.1892742219770151\n",
      "train loss:0.1489440634519254\n",
      "train loss:0.07539208306043951\n",
      "train loss:0.08388253805019323\n",
      "train loss:0.09094045491644595\n",
      "train loss:0.16793937428542105\n",
      "train loss:0.1552107092556563\n",
      "train loss:0.048546219335806724\n",
      "train loss:0.10047765145727863\n",
      "train loss:0.11446532376426471\n",
      "train loss:0.18521797042817037\n",
      "train loss:0.14840350189536733\n",
      "train loss:0.19180672050976458\n",
      "train loss:0.046058040753360806\n",
      "train loss:0.12779702412833896\n",
      "train loss:0.14494478745609332\n",
      "=== epoch:2, train acc:0.954, test acc:0.959 ===\n",
      "train loss:0.09389251172436536\n",
      "train loss:0.06757084267265757\n",
      "train loss:0.0781782094378501\n",
      "train loss:0.17027544565676758\n",
      "train loss:0.23258164856464736\n",
      "train loss:0.1149382793071716\n",
      "train loss:0.06474415044346025\n",
      "train loss:0.074559579489705\n",
      "train loss:0.11678255402263124\n",
      "train loss:0.09790422723781193\n",
      "train loss:0.07315941795420189\n",
      "train loss:0.20047734466887768\n",
      "train loss:0.048890990282889416\n",
      "train loss:0.18655227962774654\n",
      "train loss:0.11341518386351991\n",
      "train loss:0.16410593594610823\n",
      "train loss:0.07791825691777617\n",
      "train loss:0.05422809481878556\n",
      "train loss:0.19025770967874\n",
      "train loss:0.11040142053099684\n",
      "train loss:0.07014356297190184\n",
      "train loss:0.08838898185132468\n",
      "train loss:0.08853942016304782\n",
      "train loss:0.1225648176939112\n",
      "train loss:0.18564304796264663\n",
      "train loss:0.06754978949204951\n",
      "train loss:0.14878328174741465\n",
      "train loss:0.08201615940504814\n",
      "train loss:0.14772005271919156\n",
      "train loss:0.04156622863498639\n",
      "train loss:0.14178135256983043\n",
      "train loss:0.07409057073870443\n",
      "train loss:0.10078353778307539\n",
      "train loss:0.1028514767226834\n",
      "train loss:0.18394919944615637\n",
      "train loss:0.11327225825160203\n",
      "train loss:0.07146806290038937\n",
      "train loss:0.06669068140175717\n",
      "train loss:0.19672259980943418\n",
      "train loss:0.1590269067372235\n",
      "train loss:0.15578526233640058\n",
      "train loss:0.13296851255524006\n",
      "train loss:0.1566259735730877\n",
      "train loss:0.10372317805530412\n",
      "train loss:0.07946159420530256\n",
      "train loss:0.06277787293900118\n",
      "train loss:0.12705322436825492\n",
      "train loss:0.18492473572192858\n",
      "train loss:0.0847291566516055\n",
      "train loss:0.21187604106459892\n",
      "train loss:0.11813777671298194\n",
      "train loss:0.11983683927252053\n",
      "train loss:0.14694806700830523\n",
      "train loss:0.08432505440531163\n",
      "train loss:0.10213814070306652\n",
      "train loss:0.07365024580639465\n",
      "train loss:0.07768857805362508\n",
      "train loss:0.14747023572996978\n",
      "train loss:0.059332568376870294\n",
      "train loss:0.06734147359762326\n",
      "train loss:0.11864622395280841\n",
      "train loss:0.09529767732081453\n",
      "train loss:0.07900369305449068\n",
      "train loss:0.22035757472299797\n",
      "train loss:0.10930160110721329\n",
      "train loss:0.1863835704492519\n",
      "train loss:0.14335758788002914\n",
      "train loss:0.06155260743658562\n",
      "train loss:0.06029276159588439\n",
      "train loss:0.11001359759464507\n",
      "train loss:0.07099513599769146\n",
      "train loss:0.08624615809004643\n",
      "train loss:0.04752270416411165\n",
      "train loss:0.20627277452880377\n",
      "train loss:0.09851358950612221\n",
      "train loss:0.2917206448838786\n",
      "train loss:0.14918106070438958\n",
      "train loss:0.12750746308881492\n",
      "train loss:0.14317435631690553\n",
      "train loss:0.15992913089422636\n",
      "train loss:0.07935689720263599\n",
      "train loss:0.1074899767964052\n",
      "train loss:0.08417842563105385\n",
      "train loss:0.08289528089578407\n",
      "train loss:0.08263020204017729\n",
      "train loss:0.152971773829207\n",
      "train loss:0.13346682944552804\n",
      "train loss:0.2068157760479166\n",
      "train loss:0.09598775966554697\n",
      "train loss:0.1054250481920013\n",
      "train loss:0.17192632904643468\n",
      "train loss:0.11569201301126465\n",
      "train loss:0.08267379530434418\n",
      "train loss:0.20040238657317647\n",
      "train loss:0.08868409887239306\n",
      "train loss:0.1408924793386411\n",
      "train loss:0.12580159153179646\n",
      "train loss:0.04602287525329826\n",
      "train loss:0.17333761989125648\n",
      "train loss:0.13590867160989978\n",
      "train loss:0.12325467567750749\n",
      "train loss:0.18666571993456443\n",
      "train loss:0.20113277301321972\n",
      "train loss:0.25693774121364243\n",
      "train loss:0.20007961865358087\n",
      "train loss:0.14141164762774577\n",
      "train loss:0.17328082388065746\n",
      "train loss:0.11892423111781661\n",
      "train loss:0.058278506716811326\n",
      "train loss:0.0608393194682529\n",
      "train loss:0.05893490854910311\n",
      "train loss:0.1717454283456016\n",
      "train loss:0.11718615462059391\n",
      "train loss:0.14297974060844262\n",
      "train loss:0.08275478258091834\n",
      "train loss:0.161583581910805\n",
      "train loss:0.11884913090416152\n",
      "train loss:0.13232979203171558\n",
      "train loss:0.29776889950815605\n",
      "train loss:0.091391009134038\n",
      "train loss:0.12030124820701968\n",
      "train loss:0.12564907478381865\n",
      "train loss:0.0816941725249159\n",
      "train loss:0.09141974385846127\n",
      "train loss:0.1451875689835964\n",
      "train loss:0.10211084684676215\n",
      "train loss:0.10073594432234045\n",
      "train loss:0.10180312443192358\n",
      "train loss:0.0638752395770938\n",
      "train loss:0.08260098755842998\n",
      "train loss:0.03795414967180221\n",
      "train loss:0.12719717321782945\n",
      "train loss:0.06892884800844065\n",
      "train loss:0.050839821766961356\n",
      "train loss:0.123776433193597\n",
      "train loss:0.07649899495711249\n",
      "train loss:0.17301351389123826\n",
      "train loss:0.04468274650742976\n",
      "train loss:0.09317051479494584\n",
      "train loss:0.13052304130522527\n",
      "train loss:0.04918888846262029\n",
      "train loss:0.07194198636218568\n",
      "train loss:0.07301286584941356\n",
      "train loss:0.1959161597469649\n",
      "train loss:0.1363501824961288\n",
      "train loss:0.14775467706873707\n",
      "train loss:0.11847314186206125\n",
      "train loss:0.10036219905000554\n",
      "train loss:0.17421393765314833\n",
      "train loss:0.0818893314707114\n",
      "train loss:0.1487537672210192\n",
      "train loss:0.12500009654122043\n",
      "train loss:0.1439753152613915\n",
      "train loss:0.13144616737125608\n",
      "train loss:0.14391613055053537\n",
      "train loss:0.20753320784082857\n",
      "train loss:0.09695609421279838\n",
      "train loss:0.053527997917616636\n",
      "train loss:0.14467769671907546\n",
      "train loss:0.08288399430078484\n",
      "train loss:0.10374332035801469\n",
      "train loss:0.08831761667261681\n",
      "train loss:0.12072266308708995\n",
      "train loss:0.16693205623720173\n",
      "train loss:0.06275191909256252\n",
      "train loss:0.05192686102451833\n",
      "train loss:0.12483754525234646\n",
      "train loss:0.05155754092069308\n",
      "train loss:0.06499465724216093\n",
      "train loss:0.11235241581763646\n",
      "train loss:0.08466618379706084\n",
      "train loss:0.09092101249323994\n",
      "train loss:0.0576606373116252\n",
      "train loss:0.0461253558956414\n",
      "train loss:0.18099955833448111\n",
      "train loss:0.15503249811778783\n",
      "train loss:0.15235956031583278\n",
      "train loss:0.0880250455436238\n",
      "train loss:0.1193418234886197\n",
      "train loss:0.028338334268345908\n",
      "train loss:0.07180472686451228\n",
      "train loss:0.038913700064843335\n",
      "train loss:0.07673611014583485\n",
      "train loss:0.06313565218204358\n",
      "train loss:0.090166412672675\n",
      "train loss:0.1780280493001712\n",
      "train loss:0.13155567754023684\n",
      "train loss:0.13877860023659105\n",
      "train loss:0.08679328245624082\n",
      "train loss:0.06655958696725717\n",
      "train loss:0.056800986978183816\n",
      "train loss:0.09295581976815924\n",
      "train loss:0.13883969849575079\n",
      "train loss:0.15780169958003723\n",
      "train loss:0.10552158300515706\n",
      "train loss:0.10844026466016629\n",
      "train loss:0.1483753216336872\n",
      "train loss:0.08101370913295687\n",
      "train loss:0.10465760541064029\n",
      "train loss:0.10023633133973867\n",
      "train loss:0.04600583880778905\n",
      "train loss:0.1645543485555906\n",
      "train loss:0.06188045247834175\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss:0.09487588189569393\n",
      "train loss:0.13252744809706166\n",
      "train loss:0.195620051359466\n",
      "train loss:0.12847922485050178\n",
      "train loss:0.04592262919761083\n",
      "train loss:0.08036001351783825\n",
      "train loss:0.17987524506564398\n",
      "train loss:0.07516221529925246\n",
      "train loss:0.07910620098847308\n",
      "train loss:0.08414758023688003\n",
      "train loss:0.035946189450704755\n",
      "train loss:0.1335844400787167\n",
      "train loss:0.047871630288840644\n",
      "train loss:0.07755076967854531\n",
      "train loss:0.05782879246716291\n",
      "train loss:0.05060912905601622\n",
      "train loss:0.11997525265772443\n",
      "train loss:0.09572025110531009\n",
      "train loss:0.08491566359794009\n",
      "train loss:0.08855993042171187\n",
      "train loss:0.08840262147380418\n",
      "train loss:0.16437718485619499\n",
      "train loss:0.05418720259782686\n",
      "train loss:0.1929443664122905\n",
      "train loss:0.07545953072827405\n",
      "train loss:0.08091824463919847\n",
      "train loss:0.13354276713681115\n",
      "train loss:0.044238610215198045\n",
      "train loss:0.09808270031285016\n",
      "train loss:0.06300743884406593\n",
      "train loss:0.05832561016479791\n",
      "train loss:0.05730693613768146\n",
      "train loss:0.12318023358127334\n",
      "train loss:0.07609183072185577\n",
      "train loss:0.08188504144137922\n",
      "train loss:0.08476858658793932\n",
      "train loss:0.14566540958915425\n",
      "train loss:0.06365682933868504\n",
      "train loss:0.05985584556959055\n",
      "train loss:0.08362648196848871\n",
      "train loss:0.052528822022301594\n",
      "train loss:0.1575442240213588\n",
      "train loss:0.18172269239330277\n",
      "train loss:0.13666858967226583\n",
      "train loss:0.0438979524012821\n",
      "train loss:0.1025677395981306\n",
      "train loss:0.1930387059492924\n",
      "train loss:0.062492783244060934\n",
      "train loss:0.03351619449989044\n",
      "train loss:0.06206354051634651\n",
      "train loss:0.12002291933033302\n",
      "train loss:0.17061498457243207\n",
      "train loss:0.11826931725225424\n",
      "train loss:0.11895936332758879\n",
      "train loss:0.06978881807375588\n",
      "train loss:0.11338687888541346\n",
      "train loss:0.09490360732682851\n",
      "train loss:0.0954575856168583\n",
      "train loss:0.0635290990487699\n",
      "train loss:0.052683990332999996\n",
      "train loss:0.08219522075083051\n",
      "train loss:0.056341617946504385\n",
      "train loss:0.041910362969378306\n",
      "train loss:0.19936775212086438\n",
      "train loss:0.1880489600293976\n",
      "train loss:0.05324009943628532\n",
      "train loss:0.11058444572515347\n",
      "train loss:0.15830439939299545\n",
      "train loss:0.04117974462006009\n",
      "train loss:0.07577735225660619\n",
      "train loss:0.07045795445228915\n",
      "train loss:0.11797951608679241\n",
      "train loss:0.04385492420561157\n",
      "train loss:0.05032088580177584\n",
      "train loss:0.07042511714792085\n",
      "train loss:0.05704354726950492\n",
      "train loss:0.09723500928015337\n",
      "train loss:0.049223709005299064\n",
      "train loss:0.07327777124874865\n",
      "train loss:0.08963697848092846\n",
      "train loss:0.07229702667027582\n",
      "train loss:0.09363490073404654\n",
      "train loss:0.11931531817032746\n",
      "train loss:0.050391266763763376\n",
      "train loss:0.11916668008323278\n",
      "train loss:0.07202514800663008\n",
      "train loss:0.1260466954964827\n",
      "train loss:0.05517997387643321\n",
      "train loss:0.08808226947019918\n",
      "train loss:0.15449177139000414\n",
      "train loss:0.1378331192548225\n",
      "train loss:0.08091817455274558\n",
      "train loss:0.0578755555397293\n",
      "train loss:0.04647646771486595\n",
      "train loss:0.063952221069741\n",
      "train loss:0.0557734529853984\n",
      "train loss:0.1468358696150837\n",
      "train loss:0.07564924263786936\n",
      "train loss:0.06531099199727576\n",
      "train loss:0.07605875694592716\n",
      "train loss:0.06042024958541271\n",
      "train loss:0.06619754946234745\n",
      "train loss:0.09135041893955696\n",
      "train loss:0.10609016102013523\n",
      "train loss:0.10758113749341168\n",
      "train loss:0.07588849976567298\n",
      "train loss:0.04389597941456997\n",
      "train loss:0.12581574508693824\n",
      "train loss:0.10112675233385471\n",
      "train loss:0.04557493215811836\n",
      "train loss:0.08092254973077746\n",
      "train loss:0.026480147799217986\n",
      "train loss:0.06809179367651651\n",
      "train loss:0.0662456771336823\n",
      "train loss:0.07297848337488942\n",
      "train loss:0.0780140079206496\n",
      "train loss:0.07744089104851763\n",
      "train loss:0.09753195261654649\n",
      "train loss:0.0687212217174151\n",
      "train loss:0.05479302939504342\n",
      "train loss:0.06712890586457275\n",
      "train loss:0.08298570913091419\n",
      "train loss:0.13655222894453314\n",
      "train loss:0.06833019124925409\n",
      "train loss:0.06456029756947436\n",
      "train loss:0.025450469902732132\n",
      "train loss:0.0708439866370901\n",
      "train loss:0.0899585871641684\n",
      "train loss:0.090956931278048\n",
      "train loss:0.02623300132576447\n",
      "train loss:0.126077321491081\n",
      "train loss:0.05956889432802611\n",
      "train loss:0.11154465839894182\n",
      "train loss:0.1276265540469892\n",
      "train loss:0.08480393724641282\n",
      "train loss:0.063507167217606\n",
      "train loss:0.08383292444641922\n",
      "train loss:0.0636889618096565\n",
      "train loss:0.07832480791327051\n",
      "train loss:0.07300048705695943\n",
      "train loss:0.12009386076937854\n",
      "train loss:0.12251241632335891\n",
      "train loss:0.12974990808429276\n",
      "train loss:0.04033080431156553\n",
      "train loss:0.032749597774780134\n",
      "train loss:0.1383143643601998\n",
      "train loss:0.07707594760918723\n",
      "train loss:0.08251541634485063\n",
      "train loss:0.11802457496406771\n",
      "train loss:0.0719084361050542\n",
      "train loss:0.1155912378948573\n",
      "train loss:0.09338330583722508\n",
      "train loss:0.1075978585786671\n",
      "train loss:0.0702239369529496\n",
      "train loss:0.07427692541743382\n",
      "train loss:0.090762816742603\n",
      "train loss:0.07172301160787668\n",
      "train loss:0.056295211794827\n",
      "train loss:0.07635630985502044\n",
      "train loss:0.07178037712627658\n",
      "train loss:0.04918839894742977\n",
      "train loss:0.07636480359335866\n",
      "train loss:0.057324663863045015\n",
      "train loss:0.19562188505502118\n",
      "train loss:0.07582371137099035\n",
      "train loss:0.08399541456966726\n",
      "train loss:0.03524833738563094\n",
      "train loss:0.050419582269993955\n",
      "train loss:0.08403498148273755\n",
      "train loss:0.04015461157592827\n",
      "train loss:0.07017154718445881\n",
      "train loss:0.058099183751175225\n",
      "train loss:0.18810902455451298\n",
      "train loss:0.05849809614045802\n",
      "train loss:0.11709394226781544\n",
      "train loss:0.038572664516020115\n",
      "train loss:0.12415829589739967\n",
      "train loss:0.039565815277571484\n",
      "train loss:0.0865644194455696\n",
      "train loss:0.05195875185623648\n",
      "train loss:0.1889720508918126\n",
      "train loss:0.11557889272238452\n",
      "train loss:0.060399489032536106\n",
      "train loss:0.03990559116537326\n",
      "train loss:0.10772525161579875\n",
      "train loss:0.049899359761297335\n",
      "train loss:0.06664265533405303\n",
      "train loss:0.1800015987299554\n",
      "train loss:0.043894305138066976\n",
      "train loss:0.11712641818890428\n",
      "train loss:0.04651012035629916\n",
      "train loss:0.12125056021417112\n",
      "train loss:0.08348062585597962\n",
      "train loss:0.06050177754499165\n",
      "train loss:0.0742635901864729\n",
      "train loss:0.06516923779978696\n",
      "train loss:0.06525883646591216\n",
      "train loss:0.08465169838508939\n",
      "train loss:0.05713832704828036\n",
      "train loss:0.05781711055789828\n",
      "train loss:0.06768434331162293\n",
      "train loss:0.06500696655836558\n",
      "train loss:0.12602068197201924\n",
      "train loss:0.20180360323127566\n",
      "train loss:0.0735903843528949\n",
      "train loss:0.12858299536899007\n",
      "train loss:0.09745270811517409\n",
      "train loss:0.042434275973348104\n",
      "train loss:0.10067324060243407\n",
      "train loss:0.028512055855511115\n",
      "train loss:0.11520210967170258\n",
      "train loss:0.05736183747076287\n",
      "train loss:0.0821125014419094\n",
      "train loss:0.040972437728051085\n",
      "train loss:0.019899422789641005\n",
      "train loss:0.0912451507148425\n",
      "train loss:0.039964088820065226\n",
      "train loss:0.04509487730720276\n",
      "train loss:0.05079399203021314\n",
      "train loss:0.05779264928166763\n",
      "train loss:0.12641648461707208\n",
      "train loss:0.045478683296132714\n",
      "train loss:0.03143709962611875\n",
      "train loss:0.0774205000883566\n",
      "train loss:0.05056151476939138\n",
      "train loss:0.16332272267151512\n",
      "train loss:0.19963864058863293\n",
      "train loss:0.03758466397979413\n",
      "train loss:0.15684360818266335\n",
      "train loss:0.0693994749242622\n",
      "train loss:0.09860386312743506\n",
      "train loss:0.1146122163640655\n",
      "train loss:0.05820031745074021\n",
      "train loss:0.08116679607499327\n",
      "train loss:0.050007463714485695\n",
      "train loss:0.09643965599744167\n",
      "train loss:0.05476408623545235\n",
      "train loss:0.04851969985416914\n",
      "train loss:0.10208329017761734\n",
      "train loss:0.11971371822943899\n",
      "train loss:0.119111031513807\n",
      "train loss:0.09053101898510077\n",
      "train loss:0.0896841807551765\n",
      "train loss:0.08431404396895871\n",
      "train loss:0.050699906034025494\n",
      "train loss:0.03549956923646606\n",
      "train loss:0.06603316108967106\n",
      "train loss:0.062091216866697704\n",
      "train loss:0.11543211452469081\n",
      "train loss:0.06613845300058291\n",
      "train loss:0.09665470864836818\n",
      "train loss:0.11580059856447271\n",
      "train loss:0.04690494725120016\n",
      "train loss:0.063434291198119\n",
      "train loss:0.10067369771571358\n",
      "train loss:0.07901345789646251\n",
      "train loss:0.15502444399058635\n",
      "train loss:0.06864249073656374\n",
      "train loss:0.046769847134949034\n",
      "train loss:0.1444744782220759\n",
      "train loss:0.06709010842214874\n",
      "train loss:0.06228388700280408\n",
      "train loss:0.13300402946766027\n",
      "train loss:0.1906408248667044\n",
      "train loss:0.045196516671490314\n",
      "train loss:0.051066825992585343\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss:0.16289320230111323\n",
      "train loss:0.2673596598895825\n",
      "train loss:0.0482858323296094\n",
      "train loss:0.05452305966272229\n",
      "train loss:0.029881207555074014\n",
      "train loss:0.14540985524761948\n",
      "train loss:0.019999585571945845\n",
      "train loss:0.032551394029139945\n",
      "train loss:0.06950659199966268\n",
      "train loss:0.0179266908880133\n",
      "train loss:0.07087619922304939\n",
      "train loss:0.11083584992973565\n",
      "train loss:0.038671608746299754\n",
      "train loss:0.22149109551157636\n",
      "train loss:0.09666030935556119\n",
      "train loss:0.1191406165907916\n",
      "train loss:0.08543888878291007\n",
      "train loss:0.05522222286154184\n",
      "train loss:0.08138819147047299\n",
      "train loss:0.11709714190523463\n",
      "train loss:0.04647491599810363\n",
      "train loss:0.05953664872382898\n",
      "train loss:0.08918302581850795\n",
      "train loss:0.11642915901017556\n",
      "train loss:0.09245130720724809\n",
      "train loss:0.11019061356606395\n",
      "train loss:0.057619586287843465\n",
      "train loss:0.07405201021217307\n",
      "train loss:0.026568733749465032\n",
      "train loss:0.07452663644464429\n",
      "train loss:0.0725814173913966\n",
      "train loss:0.1348948853562315\n",
      "train loss:0.07097782749549221\n",
      "train loss:0.044706099527506996\n",
      "train loss:0.018608086211193683\n",
      "train loss:0.04558442306226133\n",
      "train loss:0.0761409282100956\n",
      "train loss:0.10307352073206344\n",
      "train loss:0.0769092481263935\n",
      "train loss:0.13249562042867052\n",
      "train loss:0.06523119314817215\n",
      "train loss:0.02523658447621294\n",
      "train loss:0.09682197563634651\n",
      "train loss:0.0903814958406766\n",
      "train loss:0.048870838649334586\n",
      "train loss:0.07295960719378278\n",
      "train loss:0.10351583755393666\n",
      "train loss:0.0486782089108216\n",
      "train loss:0.15946921946839562\n",
      "train loss:0.03753525406358638\n",
      "train loss:0.05525853484126687\n",
      "train loss:0.0709801587595915\n",
      "train loss:0.07303947676560155\n",
      "train loss:0.07401612958082276\n",
      "train loss:0.09087912450040994\n",
      "train loss:0.0682065698866337\n",
      "train loss:0.014641908327825266\n",
      "train loss:0.10958550271013649\n",
      "train loss:0.03351250499214673\n",
      "train loss:0.08805865601458207\n",
      "train loss:0.06997536431981435\n",
      "train loss:0.05613901781312438\n",
      "train loss:0.04848971025048823\n",
      "train loss:0.13476529805995985\n",
      "train loss:0.08845837193717122\n",
      "train loss:0.0632647805249091\n",
      "train loss:0.07343981958846892\n",
      "train loss:0.08996090087950125\n",
      "train loss:0.12943380022722006\n",
      "train loss:0.07320748352202465\n",
      "train loss:0.052397564102774394\n",
      "train loss:0.05536821717948267\n",
      "train loss:0.061815658449400415\n",
      "train loss:0.0611650620565351\n",
      "train loss:0.07625557565624114\n",
      "train loss:0.06348163348663181\n",
      "train loss:0.02364449107765582\n",
      "train loss:0.092433725906731\n",
      "train loss:0.09335593912374893\n",
      "train loss:0.08853480659120479\n",
      "train loss:0.04954685775995665\n",
      "train loss:0.13356317649433938\n",
      "train loss:0.09708945903348033\n",
      "train loss:0.05154783597951283\n",
      "train loss:0.07397005582003051\n",
      "train loss:0.09936842944690064\n",
      "train loss:0.064795488382321\n",
      "train loss:0.0666755102589632\n",
      "train loss:0.050523983493628494\n",
      "train loss:0.04760183588891117\n",
      "train loss:0.020320473298648837\n",
      "train loss:0.024976947636079563\n",
      "train loss:0.03910086764227273\n",
      "train loss:0.05621119300142736\n",
      "train loss:0.23267065585188423\n",
      "train loss:0.08065101057327363\n",
      "train loss:0.062490324008498924\n",
      "train loss:0.04769469384055996\n",
      "train loss:0.02029189732763313\n",
      "train loss:0.02231138884939782\n",
      "train loss:0.09159252433071174\n",
      "train loss:0.044449371433034617\n",
      "train loss:0.032576324136840314\n",
      "train loss:0.03647194731778068\n",
      "train loss:0.014970550342870424\n",
      "train loss:0.1105299087964156\n"
     ]
    }
   ],
   "source": [
    "# coding: utf-8\n",
    "import sys, os\n",
    "sys.path.append(os.pardir)  # 親ディレクトリのファイルをインポートするための設定\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from dataset.mnist import load_mnist\n",
    "from ch07.simple_convnet import SimpleConvNet\n",
    "from common.trainer import Trainer\n",
    "%matplotlib inline\n",
    "\n",
    "# データの読み込み\n",
    "(x_train, t_train), (x_test, t_test) = load_mnist(flatten=False)\n",
    "\n",
    "# 処理に時間のかかる場合はデータを削減 \n",
    "#x_train, t_train = x_train[:5000], t_train[:5000]\n",
    "x_test, t_test = x_test[:1000], t_test[:1000]\n",
    "\n",
    "max_epochs = 20\n",
    "\n",
    "network = SimpleConvNet(input_dim=(1,28,28), \n",
    "                        conv_param = {'filter_num': 30, 'filter_size': 5, 'pad': 0, 'stride': 1},\n",
    "                        hidden_size=100, output_size=10, weight_init_std=0.01)\n",
    "                        \n",
    "trainer = Trainer(network, x_train, t_train, x_test, t_test,\n",
    "                  epochs=max_epochs, mini_batch_size=100,\n",
    "                  optimizer='Adam', optimizer_param={'lr': 0.001},\n",
    "                  evaluate_sample_num_per_epoch=1000)\n",
    "trainer.train()\n",
    "\n",
    "# パラメータの保存\n",
    "network.save_params(\"params.pkl\")\n",
    "print(\"Saved Network Parameters!\")\n",
    "\n",
    "# グラフの描画\n",
    "markers = {'train': 'o', 'test': 's'}\n",
    "x = np.arange(max_epochs)\n",
    "plt.plot(x, trainer.train_acc_list, marker='o', label='train', markevery=2)\n",
    "plt.plot(x, trainer.test_acc_list, marker='s', label='test', markevery=2)\n",
    "plt.xlabel(\"epochs\")\n",
    "plt.ylabel(\"accuracy\")\n",
    "plt.ylim(0, 1.0)\n",
    "plt.legend(loc='lower right')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
